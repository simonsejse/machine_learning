{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc651be2-7486-4917-9001-7e2306a9d702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from IPython.display import display, Markdown, HTML, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b606bfda",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#2b2b2b; padding: 20px; border-radius: 8px; color: #d3d3d3; font-family: Arial, sans-serif;\">\n",
    "    <h2 style=\"color: #80cbc4; text-align: center;\">Setup</h2>\n",
    "    <h3 style=\"color: #ffab91; text-align: center;\">Layers</h3>\n",
    "    <ul style=\"line-height: 1.6; font-size: 1.05em;\">\n",
    "        <li><strong>1st layer (Input layer)</strong>: 784 neurons / input neurons</li>\n",
    "        <li><strong>2nd layer (1st Hidden layer)</strong>: 16 neurons</li>\n",
    "        <li><strong>3rd layer (2nd Hidden layer)</strong>: 16 neurons</li>\n",
    "        <li><strong>4th layer (Output layer)</strong>: 10 neurons (0-9 digit classification)</li>\n",
    "    </ul>\n",
    "    <p style=\"font-size: 1.1em; text-align: center; color: #b0bec5;\">\n",
    "        <strong>Total parameters:</strong> 16 * 784 + 16 * 16 + 16 * 10 + (16 * 2 + 10) = 13,002\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7fa11ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (60000, 28, 28)\n",
      "y_train.shape: (60000,)\n",
      "x_test.shape: (10000, 28, 28)\n",
      "y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('x_train.shape:', X_train.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print('x_test.shape:', X_test.shape)\n",
    "print('y_test.shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd4cf016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5337.227589993476\n",
      "Epoch 2, Loss: 2877.8488060064014\n",
      "Epoch 3, Loss: 2517.8299143359354\n",
      "Epoch 4, Loss: 2341.512254995792\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 155\u001b[0m\n\u001b[0;32m    153\u001b[0m   b3 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m*\u001b[39m grad_b3\n\u001b[0;32m    154\u001b[0m   w4 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m*\u001b[39m grad_w4\n\u001b[1;32m--> 155\u001b[0m   b4 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m*\u001b[39m grad_b4\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_loss \u001b[38;5;241m<\u001b[39m best_total_loss:\n\u001b[0;32m    158\u001b[0m   best_total_loss, patience_counter \u001b[38;5;241m=\u001b[39m total_loss, \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: Improve this to classes like, Layer, Neuron, etc.\n",
    "class Neuron:\n",
    "  def __init__(self, nin):\n",
    "    self.w = np.random.uniform(1, -1, nin)\n",
    "    self.b = np.random.uniform(1, -1)\n",
    "  def __repr__(self):\n",
    "    return rf\"Neuron(w={self.w.shape}, b={self.b:.4f})\"\n",
    "\n",
    "class Layer:\n",
    "  def __init__(self, nn, nin):\n",
    "    self.neurons = [Neuron(nin) for _ in range(nn)]\n",
    "\n",
    "def display_image(X, y, idx, ax):\n",
    "  image = X[idx]\n",
    "  true_number = y[idx]\n",
    "  ax.imshow(image, cmap='gray', interpolation='nearest')\n",
    "  ax.axis('off') \n",
    "  if isinstance(ax, plt.Axes):\n",
    "    ax.set_title(f\"True Number: {true_number}\", fontsize=12)\n",
    "\n",
    "def display_number_as_img(X, y, num):\n",
    "  indices = [i for i in range(len(X)) if num == y[i]]\n",
    "  samples = np.random.choice(indices, 10, replace=False)\n",
    "  fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "  fig.tight_layout(pad=3)\n",
    "  for i in range(10):\n",
    "      ax = axes[i // 5, i % 5]\n",
    "      display_image(X, y, samples[i], ax)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def init_params():\n",
    "  w2 = np.random.uniform(-0.1, 0.1, (16, 784))\n",
    "  b2 = np.zeros(16)\n",
    "  w3 = np.random.uniform(-0.1, 0.1, (16, 16)) \n",
    "  b3 = np.zeros(16)\n",
    "  w4 = np.random.uniform(-0.1, 0.1, (10, 16))\n",
    "  b4 = np.zeros(10)\n",
    "  return w2, b2, w3, b3, w4, b4\n",
    "\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "  z = z - np.max(z) # shifts everything left, so maximum value becomes zero\n",
    "  z = np.exp(z)\n",
    "  a = z / np.sum(z)\n",
    "  return a\n",
    "\n",
    "def dsoftmax(z):\n",
    "    s = softmax(z).reshape(-1, 1) \n",
    "    return np.diagflat(s) - np.dot(s, s.T)\n",
    "\n",
    "def dReLu(z):\n",
    "  return z > 0\n",
    "\n",
    "def ReLu(z): \n",
    "  return np.maximum(0, z)\n",
    "\n",
    "def one_hot_encode(y, size):\n",
    "  row_size, _ = size\n",
    "  one_hot = np.zeros(size)\n",
    "  one_hot[np.arange(0, row_size), y] = 1 \n",
    "  return one_hot\n",
    "\n",
    "def cross_entropy_loss(y, a4):\n",
    "    return -np.sum(y * np.log(a4 + 1e-8))  \n",
    "\n",
    "# TODO: Improve by X being multiple images\n",
    "def feed_forward(X, w2, b2, w3, b3, w4, b4):\n",
    "  X_flat = X.flatten()\n",
    "\n",
    "  z2 = w2.dot(X_flat) + b2\n",
    "  a2 = ReLu(z2)\n",
    "  \n",
    "  z3 = w3.dot(a2) + b3\n",
    "  a3 = ReLu(z3)\n",
    "  \n",
    "  z4 = w4.dot(a3) + b4\n",
    "  a4 = softmax(z4)\n",
    "\n",
    "  return a4, z4, a3, z3, a2, z2, X_flat\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "k = 10\n",
    "def backprop(y, a4, z4, a3, z3, a2, z2, w4, w3, w2, X_flat):\n",
    "  # output layer\n",
    "  delta4 = (a4 - y)\n",
    "\n",
    "  grad_w4 = np.outer(delta4, a3)\n",
    "  grad_b4 = delta4\n",
    "\n",
    "                   \n",
    "  # 2nd hidden layer\n",
    "  delta3 = np.dot(delta4, w4) * dReLu(z3)\n",
    "  grad_w3 = np.outer(delta3, a2)\n",
    "  grad_b3 = delta3\n",
    "\n",
    "\n",
    "  # 1st hidden layer\n",
    "  delta2 = np.dot(delta3, w3) * dReLu(z2)\n",
    "  grad_w2 = np.outer(delta2, X_flat)\n",
    "  grad_b2 = delta2\n",
    "\n",
    "  # print(\"w4 shape \", w4.shape)\n",
    "  # print(\"y shape \", y.shape)\n",
    "  # print(\"a4 shape \", a4.shape)\n",
    "  # print(\"delta4 shape \", delta4.shape)\n",
    "  # print(\"grad_w4 shape \", grad_w4.shape)\n",
    "  # print(\"b4 shape \", grad_b4.shape)\n",
    "\n",
    "  # print(\"a3 shape \", a3.shape)\n",
    "  # print(\"delta3 shape \", delta3.shape)\n",
    "  # print(\"grad_w3 shape \", grad_w3.shape)\n",
    "  # print(\"b3 shape \", grad_b3.shape)\n",
    "\n",
    "  # print(\"delta2 shape \", delta2.shape)\n",
    "  # print(\"grad_w2 shape \", grad_w2.shape)\n",
    "  # print(\"b2 shape \", grad_b2.shape)\n",
    "\n",
    "  # print(LOLbreak)\n",
    "  return grad_w2, grad_b2, grad_w3, grad_b3, grad_w4, grad_b4\n",
    "\n",
    "w2, b2, w3, b3, w4, b4 = init_params()\n",
    "y_train_hot = one_hot_encode(y_train, (60000, y_train.max() + 1))\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "\n",
    "max_patience = 100\n",
    "patience_counter = 0\n",
    "best_total_loss = np.inf\n",
    "best_parameters = None\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  total_loss = 0\n",
    "  i = 0\n",
    "  for x, y in zip(X_train, y_train_hot): \n",
    "    #feed forward\n",
    "    a4, z4, a3, z3, a2, z2, X_flat = feed_forward(x, w2, b2, w3, b3, w4, b4) \n",
    "    loss = 1/2 * np.sum((y - a4)**2)\n",
    "\n",
    "    total_loss += loss\n",
    "\n",
    "    #backprop\n",
    "    grad_w2, grad_b2, grad_w3, grad_b3, grad_w4, grad_b4 = backprop(\n",
    "            y, a4, z4, a3, z3, a2, z2, w4, w3, w2, X_flat)\n",
    "\n",
    "    #update weights\n",
    "    w2 -= lr * grad_w2\n",
    "    b2 -= lr * grad_b2\n",
    "    w3 -= lr * grad_w3\n",
    "    b3 -= lr * grad_b3\n",
    "    w4 -= lr * grad_w4\n",
    "    b4 -= lr * grad_b4\n",
    "\n",
    "  if total_loss < best_total_loss:\n",
    "    best_total_loss, patience_counter = total_loss, 0\n",
    "    best_parameters = (w2, b2, w3, b3, w4, b4)\n",
    "  elif (patience_counter := patience_counter + 1) == max_patience:\n",
    "    break\n",
    "  \n",
    "  print(f\"Epoch {epoch + 1}, Loss: {total_loss}\")\n",
    "  \n",
    "correct_predictions = 0\n",
    "total_predictions = len(X_test)\n",
    "\n",
    "params_required = {'accuracy', 'w2', 'b2', 'w3', 'b3', 'w4', 'b4'}\n",
    "def save_weights(**params):\n",
    "\n",
    "  if not params_required.issubset(params.keys()):\n",
    "    raise ValueError(f\"Required parameters are {params_required}, you are missing {params_required.difference(params)}\")\n",
    "    \n",
    "  accuracy = params.get('accuracy', -1)\n",
    "  best_accuracy = -1\n",
    "  if os.path.exists('weights.npz'):\n",
    "    data = np.load('weights.npz')\n",
    "    best_accuracy = data.get('accuracy', -1)\n",
    "\n",
    "  if accuracy <= best_accuracy:\n",
    "    print(\"Weights not saved, accuracy is not better than previous\")\n",
    "    return\n",
    "  \n",
    "  best_accuracy = accuracy\n",
    "  np.savez(\"weights.npz\", **params)\n",
    "  print(\"Weights saved successfully previous accuracy was\", best_accuracy, \"new accuracy is\", accuracy)\n",
    "  print(\"Improved by \", accuracy - best_accuracy)\n",
    "\n",
    "\n",
    "for x, y_true in zip(X_test, y_test):\n",
    "    a4, _, _, _, _, _, _ = feed_forward(x, *best_parameters)\n",
    "    t = np.argmax(a4)\n",
    "    if t == y_true:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / total_predictions * 100\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "params = dict(zip([*params_required], (accuracy, *best_parameters)))\n",
    "save_weights(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load weights\n",
    "params = np.load(\"weights.npz\")\n",
    "acc, w2, b2, w3, b3, w4, b4 = [params[key] for key in params_required]\n",
    "print(\"Test Accuracy\", acc)\n",
    "idx = 323\n",
    "\n",
    "a4, _, _, _, _, _, _= feed_forward(X_test[idx], w2, b2, w3, b3, w4, b4)\n",
    "predicted_number = np.argmax(a4)\n",
    "print(\"Number predicted is\", predicted_number)\n",
    "display_image(X_test, y_test, idx, plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376248ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Set up display\n",
    "width, height = 280, 280  # 10x scale for better visibility\n",
    "screen = pygame.display.set_mode((width, height))\n",
    "pygame.display.set_caption(\"28x28 Drawing Grid\")\n",
    "\n",
    "# Initialize grid\n",
    "grid = np.zeros((28, 28))\n",
    "\n",
    "# Main loop\n",
    "running = True\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif pygame.mouse.get_pressed()[0]:  # Left mouse button is pressed\n",
    "            x, y = pygame.mouse.get_pos()\n",
    "            grid_x, grid_y = x // 10, y // 10  # Scale down to 28x28\n",
    "            if 0 <= grid_x < 28 and 0 <= grid_y < 28:\n",
    "                grid[grid_y, grid_x] = 1  # Set grid cell to white\n",
    "\n",
    "    # Draw the grid\n",
    "    screen.fill((0, 0, 0))  # Black background\n",
    "    for y in range(28):\n",
    "        for x in range(28):\n",
    "            color = int(grid[y, x] * 255)\n",
    "            pygame.draw.rect(screen, (color, color, color), (x * 10, y * 10, 10, 10))\n",
    "    \n",
    "    pygame.display.flip()\n",
    "\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642661e1-c52f-44ba-acb7-5603145b2255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
