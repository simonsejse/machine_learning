{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc651be2-7486-4917-9001-7e2306a9d702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from IPython.display import display, Markdown, HTML, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b606bfda",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#2b2b2b; padding: 20px; border-radius: 8px; color: #d3d3d3; font-family: Arial, sans-serif;\">\n",
    "    <h2 style=\"color: #80cbc4; text-align: center;\">Setup</h2>\n",
    "    <h3 style=\"color: #ffab91; text-align: center;\">Layers</h3>\n",
    "    <ul style=\"line-height: 1.6; font-size: 1.05em;\">\n",
    "        <li><strong>1st layer (Input layer)</strong>: 784 neurons / input neurons</li>\n",
    "        <li><strong>2nd layer (1st Hidden layer)</strong>: 16 neurons</li>\n",
    "        <li><strong>3rd layer (2nd Hidden layer)</strong>: 16 neurons</li>\n",
    "        <li><strong>4th layer (Output layer)</strong>: 10 neurons (0-9 digit classification)</li>\n",
    "    </ul>\n",
    "    <p style=\"font-size: 1.1em; text-align: center; color: #b0bec5;\">\n",
    "        <strong>Total parameters:</strong> 16 * 784 + 16 * 16 + 16 * 10 + (16 * 2 + 10) = 13,002\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa11ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (60000, 784)\n",
      "y_train.shape: (60000,)\n",
      "x_test.shape: (10000, 784)\n",
      "y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# Preprocessing the dataset\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print('x_train.shape:', X_train.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print('x_test.shape:', X_test.shape)\n",
    "print('y_test.shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b69b560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Improve this to classes like, Layer, Neuron, etc.\n",
    "params_required = ['accuracy', 'w2', 'b2', 'w3', 'b3', 'w4', 'b4']\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "  def __init__(self, nin):\n",
    "    self.w = np.random.uniform(1, -1, nin)\n",
    "    self.b = np.random.uniform(1, -1)\n",
    "  def __repr__(self):\n",
    "    return rf\"Neuron(w={self.w.shape}, b={self.b:.4f})\"\n",
    "\n",
    "class Layer:\n",
    "  def __init__(self, nn, nin):\n",
    "    self.neurons = [Neuron(nin) for _ in range(nn)]\n",
    "\n",
    "def display_image(X, y, idx, ax):\n",
    "  image = X[idx]\n",
    "  true_number = y[idx]\n",
    "  ax.imshow(image, cmap='gray', interpolation='nearest')\n",
    "  ax.axis('off') \n",
    "  if isinstance(ax, plt.Axes):\n",
    "    ax.set_title(f\"True Number: {true_number}\", fontsize=12)\n",
    "\n",
    "def display_number_as_img(X, y, num):\n",
    "  indices = [i for i in range(len(X)) if num == y[i]]\n",
    "  samples = np.random.choice(indices, 10, replace=False)\n",
    "  fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "  fig.tight_layout(pad=3)\n",
    "  for i in range(10):\n",
    "      ax = axes[i // 5, i % 5]\n",
    "      display_image(X, y, samples[i], ax)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def init_params():\n",
    "  w2 = np.random.uniform(-0.1, 0.1, (100, 784))\n",
    "  b2 = np.zeros(100)\n",
    "  w3 = np.random.uniform(-0.1, 0.1, (100, 100)) \n",
    "  b3 = np.zeros(100)\n",
    "  w4 = np.random.uniform(-0.1, 0.1, (10, 100))\n",
    "  b4 = np.zeros(10)\n",
    "  return w2, b2, w3, b3, w4, b4\n",
    "\n",
    "def softmax(z):\n",
    "  z = z - np.max(z) # shifts everything left, so maximum value becomes zero\n",
    "  z = np.exp(z)\n",
    "  a = z / np.sum(z)\n",
    "  return a\n",
    "\n",
    "def dsoftmax(z):\n",
    "    s = softmax(z).reshape(-1, 1) \n",
    "    return np.diagflat(s) - np.dot(s, s.T)\n",
    "\n",
    "def dReLu(z):\n",
    "  return z > 0\n",
    "\n",
    "def ReLu(z): \n",
    "  return np.maximum(0, z)\n",
    "\n",
    "def one_hot_encode(y, size):\n",
    "  row_size, _ = size\n",
    "  one_hot = np.zeros(size)\n",
    "  one_hot[np.arange(0, row_size), y] = 1 \n",
    "  return one_hot\n",
    "\n",
    "def cross_entropy_loss(y, a4):\n",
    "    return -np.sum(y * np.log(a4 + 1e-8))  \n",
    "\n",
    "def feed_forward(X, w2, b2, w3, b3, w4, b4):\n",
    "  X_flat = X.flatten()\n",
    "\n",
    "  z2 = w2.dot(X_flat) + b2\n",
    "  a2 = ReLu(z2)\n",
    "  \n",
    "  z3 = w3.dot(a2) + b3\n",
    "  a3 = ReLu(z3)\n",
    "  \n",
    "  z4 = w4.dot(a3) + b4\n",
    "  a4 = softmax(z4)\n",
    "\n",
    "  return a4, z4, a3, z3, a2, z2, X_flat\n",
    "\n",
    "k = 10\n",
    "def backprop(y, a4, z4, a3, z3, a2, z2, w4, w3, w2, X_flat):\n",
    "  # output layer\n",
    "  delta4 = (a4 - y)\n",
    "\n",
    "  grad_w4 = np.outer(delta4, a3)\n",
    "  grad_b4 = delta4\n",
    "\n",
    "                   \n",
    "  # 2nd hidden layer\n",
    "  delta3 = np.dot(delta4, w4) * dReLu(z3)\n",
    "  grad_w3 = np.outer(delta3, a2)\n",
    "  grad_b3 = delta3\n",
    "\n",
    "\n",
    "  # 1st hidden layer\n",
    "  delta2 = np.dot(delta3, w3) * dReLu(z2)\n",
    "  grad_w2 = np.outer(delta2, X_flat)\n",
    "  grad_b2 = delta2\n",
    "  return grad_w2, grad_b2, grad_w3, grad_b3, grad_w4, grad_b4\n",
    "\n",
    "def save_weights(**params):\n",
    "\n",
    "  if not set(params_required).issubset(params.keys()):\n",
    "    missing_params = set(params_required).difference(params.keys())\n",
    "    raise ValueError(f\"Missing parameters: {missing_params}\")\n",
    "    \n",
    "  accuracy = params.get('accuracy', -1)\n",
    "  \n",
    "  best_accuracy = 0\n",
    "  if os.path.exists('weights.npz'):\n",
    "    data = np.load('weights.npz')\n",
    "    best_accuracy = data.get('accuracy', 0)\n",
    "\n",
    "  if accuracy <= best_accuracy:\n",
    "    print(\"Weights not saved, accuracy is not better than previous\")\n",
    "    return\n",
    "  \n",
    "  np.savez(\"weights.npz\", **params)\n",
    "  print(\"Weights saved successfully previous accuracy was\", best_accuracy, \"new accuracy is\", accuracy)\n",
    "  print(f\"Improved by {accuracy - best_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd4cf016",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_train, y_train_hot): \n\u001b[0;32m     15\u001b[0m   \u001b[38;5;66;03m#feed forward\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m   a4, z4, a3, z3, a2, z2, X_flat \u001b[38;5;241m=\u001b[39m \u001b[43mfeed_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb4\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     17\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum((y \u001b[38;5;241m-\u001b[39m a4)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     19\u001b[0m   total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "Cell \u001b[1;32mIn[30], line 73\u001b[0m, in \u001b[0;36mfeed_forward\u001b[1;34m(X, w2, b2, w3, b3, w4, b4)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward\u001b[39m(X, w2, b2, w3, b3, w4, b4):\n\u001b[0;32m     71\u001b[0m   X_flat \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m---> 73\u001b[0m   z2 \u001b[38;5;241m=\u001b[39m \u001b[43mw2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_flat\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b2\n\u001b[0;32m     74\u001b[0m   a2 \u001b[38;5;241m=\u001b[39m ReLu(z2)\n\u001b[0;32m     76\u001b[0m   z3 \u001b[38;5;241m=\u001b[39m w3\u001b[38;5;241m.\u001b[39mdot(a2) \u001b[38;5;241m+\u001b[39m b3\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "w2, b2, w3, b3, w4, b4 = init_params()\n",
    "y_train_hot = one_hot_encode(y_train, (60000, y_train.max() + 1))\n",
    "lr = 0.01\n",
    "epochs = 10\n",
    "\n",
    "max_patience = 15\n",
    "patience_counter = 0\n",
    "best_total_loss = np.inf\n",
    "best_parameters = None\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  total_loss = 0\n",
    "  i = 0\n",
    "  for x, y in zip(X_train, y_train_hot): \n",
    "    #feed forward\n",
    "    a4, z4, a3, z3, a2, z2, X_flat = feed_forward(x, w2, b2, w3, b3, w4, b4) \n",
    "    loss = 1/2 * np.sum((y - a4)**2)\n",
    "\n",
    "    total_loss += loss\n",
    "\n",
    "    #backprop\n",
    "    grad_w2, grad_b2, grad_w3, grad_b3, grad_w4, grad_b4 = backprop(\n",
    "            y, a4, z4, a3, z3, a2, z2, w4, w3, w2, X_flat)\n",
    "\n",
    "    #update weights\n",
    "    w2 -= lr * grad_w2\n",
    "    b2 -= lr * grad_b2\n",
    "    w3 -= lr * grad_w3\n",
    "    b3 -= lr * grad_b3\n",
    "    w4 -= lr * grad_w4\n",
    "    b4 -= lr * grad_b4\n",
    "\n",
    "  if total_loss < best_total_loss:\n",
    "    best_total_loss, patience_counter = total_loss, 0\n",
    "    best_parameters = (w2, b2, w3, b3, w4, b4)\n",
    "  elif (patience_counter := patience_counter + 1) == max_patience:\n",
    "    break\n",
    "  \n",
    "  print(f\"Epoch {epoch + 1}, Loss: {total_loss}\")\n",
    "  \n",
    "correct_predictions = 0\n",
    "total_predictions = len(X_test)\n",
    "\n",
    "for x, y_true in zip(X_test, y_test):\n",
    "    a4, _, _, _, _, _, _ = feed_forward(x, *best_parameters)\n",
    "    t = np.argmax(a4)\n",
    "    if t == y_true:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / total_predictions * 100\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "params = dict(zip([*params_required], (accuracy, *best_parameters)))\n",
    "save_weights(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2951f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number predicted is 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load weights\n",
    "params = np.load(\"weights.npz\")\n",
    "acc, w2, b2, w3, b3, w4, b4 = [params[key] for key in params.keys()]\n",
    "idx = 31\n",
    "a4, _, _, _, _, _, _= feed_forward(X_test[idx], w2, b2, w3, b3, w4, b4)\n",
    "predicted_number = np.argmax(a4)\n",
    "print(\"Number predicted is\", predicted_number)\n",
    "display_image(X_test, y_test, idx, plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376248ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities: [1.25827856e-04 2.99583427e-03 6.42579533e-03 9.75253657e-01\n",
      " 3.73823878e-04 4.00144931e-03 2.43736820e-04 8.03902193e-04\n",
      " 8.47369657e-03 1.30227687e-03]\n",
      "Number predicted is 3 with probability 97.53%\n",
      "Predicted probabilities: [3.90109372e-06 9.57492188e-01 9.31030471e-03 7.68631669e-03\n",
      " 4.56102158e-04 2.18225018e-04 3.29571151e-04 8.32895019e-03\n",
      " 1.58688834e-02 3.05557174e-04]\n",
      "Number predicted is 1 with probability 95.75%\n",
      "Predicted probabilities: [6.92551329e-06 9.76394531e-01 3.78582651e-03 3.27875035e-03\n",
      " 8.52518040e-04 4.16304188e-04 5.67958378e-04 6.03183743e-03\n",
      " 8.27121565e-03 3.94132583e-04]\n",
      "Number predicted is 1 with probability 97.64%\n",
      "Predicted probabilities: [2.33787249e-05 9.60613323e-01 1.35047897e-02 1.80576464e-03\n",
      " 1.34771808e-03 7.41810980e-04 1.49330062e-03 7.69395900e-03\n",
      " 1.25318982e-02 2.44056905e-04]\n",
      "Number predicted is 1 with probability 96.06%\n",
      "Predicted probabilities: [0.00411586 0.58269653 0.05084775 0.05281928 0.02707142 0.06476728\n",
      " 0.05389469 0.03903587 0.11315453 0.01159681]\n",
      "Number predicted is 1 with probability 58.27%\n",
      "Predicted probabilities: [1.02598582e-04 9.25761683e-01 1.83642452e-02 6.72995002e-03\n",
      " 4.14440541e-03 2.15439376e-03 3.00004160e-03 1.83280088e-02\n",
      " 1.99810383e-02 1.43363534e-03]\n",
      "Number predicted is 1 with probability 92.58%\n",
      "Predicted probabilities: [2.27889656e-04 8.92560096e-01 1.60673782e-02 1.70036730e-02\n",
      " 7.21919927e-03 4.65149074e-03 5.05827647e-03 2.76548231e-02\n",
      " 2.55590775e-02 3.99809620e-03]\n",
      "Number predicted is 1 with probability 89.26%\n",
      "Predicted probabilities: [0.0005546  0.07761939 0.00800645 0.43900866 0.0023629  0.215448\n",
      " 0.01488724 0.00137746 0.23525018 0.00548512]\n",
      "Number predicted is 3 with probability 43.90%\n",
      "Predicted probabilities: [0.00050887 0.02402423 0.0777512  0.09955168 0.07276978 0.00109302\n",
      " 0.00127688 0.2909994  0.07847743 0.35354751]\n",
      "Number predicted is 9 with probability 35.35%\n",
      "Predicted probabilities: [4.95364877e-04 4.29650456e-02 8.50800538e-03 7.94587793e-02\n",
      " 4.90614670e-03 6.49280798e-01 1.25832300e-01 7.41218019e-04\n",
      " 8.70116163e-02 8.00725683e-04]\n",
      "Number predicted is 5 with probability 64.93%\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom, gaussian_filter\n",
    "\n",
    "def center_and_scale_grid(grid):\n",
    "    if not np.any(grid):\n",
    "        return grid\n",
    "    \n",
    "    rows = np.any(grid, axis=1)\n",
    "    cols = np.any(grid, axis=0)\n",
    "    \n",
    "    y_min, y_max = np.where(rows)[0][[0, -1]]\n",
    "    x_min, x_max = np.where(cols)[0][[0, -1]]\n",
    "    \n",
    "    cropped_grid = grid[y_min:y_max+1, x_min:x_max+1]\n",
    "    \n",
    "    max_dim = max(cropped_grid.shape)\n",
    "    scaling_factor = 20.0 / max_dim\n",
    "    resized_grid = zoom(cropped_grid, scaling_factor)\n",
    "    \n",
    "    # Calculate padding to center the digit in a 28x28 grid\n",
    "    h_padding = (28 - resized_grid.shape[0]) // 2\n",
    "    v_padding = (28 - resized_grid.shape[1]) // 2\n",
    "    \n",
    "    # Create a new 28x28 grid and place the resized digit\n",
    "    new_grid = np.zeros((28, 28))\n",
    "    new_grid[h_padding:h_padding+resized_grid.shape[0], v_padding:v_padding+resized_grid.shape[1]] = resized_grid\n",
    "    \n",
    "    return new_grid\n",
    "\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "scale = 15\n",
    "width, height = 28 * scale, 28 * scale\n",
    "screen = pygame.display.set_mode((width, height))\n",
    "pygame.display.set_caption(\"Draw a Digit (Press Enter to Predict, 'C' to Clear)\")\n",
    "\n",
    "grid = np.zeros((28, 28))\n",
    "\n",
    "brush_size = 2 \n",
    "\n",
    "font_xl = pygame.font.Font(None, 36)\n",
    "font_sm = pygame.font.Font(None, 25)\n",
    "\n",
    "def draw_grayscale(x, y):\n",
    "    if 0 <= x < 28 and 0 <= y < 28:\n",
    "        grid[y, x] = min(1.0, grid[y, x] + 0.3)\n",
    "\n",
    "def probability_to_rgb(prob):\n",
    "    return (255 * (1 - prob), 0, 255 * prob)\n",
    "\n",
    "running = True\n",
    "predict = False\n",
    "prediction_text = \"\"\n",
    "predicted_probabilities = None\n",
    "\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        \n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            if event.key == pygame.K_RETURN:\n",
    "                predict = True \n",
    "            elif event.key == pygame.K_c:\n",
    "                grid = np.zeros((28, 28))\n",
    "                prediction_text = \"\"\n",
    "                predicted_probabilities = None\n",
    "        \n",
    "        elif pygame.mouse.get_pressed()[0]:  \n",
    "            x, y = pygame.mouse.get_pos()\n",
    "            grid_x, grid_y = x // scale, y // scale \n",
    "            draw_grayscale(grid_x, grid_y)\n",
    "    \n",
    "    screen.fill((0, 0, 0)) \n",
    "    for y in range(28):\n",
    "        for x in range(28):\n",
    "            color = int(grid[y, x] * 255)\n",
    "            pygame.draw.rect(screen, (color, color, color), (x * scale, y * scale, scale, scale))\n",
    "    if prediction_text:\n",
    "        text_surface = font_xl.render(prediction_text, True, (255, 255, 255))\n",
    "        screen.blit(text_surface, (10, 10))\n",
    "    \n",
    "    if predicted_probabilities is not None:\n",
    "        for i, prob in enumerate(predicted_probabilities):\n",
    "            color = probability_to_rgb(prob)\n",
    "            t = font_sm.render(f\"{i}: {prob:.2f}\", True, (255, 255, 255), color)\n",
    "            screen.blit(t, (10, 11 + (i + 1) * 36))\n",
    "    \n",
    "    pygame.display.flip()\n",
    "\n",
    "    if predict:\n",
    "        centered_grid = center_and_scale_grid(grid)\n",
    "        normalized_grid = centered_grid / np.max(centered_grid) if np.max(centered_grid) > 0 else centered_grid\n",
    "        blurred_grid = gaussian_filter(normalized_grid, sigma=0.5)\n",
    "        input_vector = blurred_grid.flatten()\n",
    "        \n",
    "        a4, _, _, _, _, _, _ = feed_forward(input_vector, w2, b2, w3, b3, w4, b4)\n",
    "        \n",
    "        predicted_probabilities = a4\n",
    "        predicted_number = np.argmax(predicted_probabilities)\n",
    "        confidence = predicted_probabilities[predicted_number] * 100  \n",
    "        \n",
    "        prediction_text = f\"Prediction: {predicted_number} ({confidence:.2f}%)\"\n",
    "        print(\"Predicted probabilities:\", predicted_probabilities)\n",
    "        print(f\"Number predicted is {predicted_number} with probability {confidence:.2f}%\")\n",
    "        \n",
    "        predict = False  # Reset the flag\n",
    "\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642661e1-c52f-44ba-acb7-5603145b2255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
